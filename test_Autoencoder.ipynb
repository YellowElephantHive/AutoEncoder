{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 38,
            "source": [
                "import os\n",
                "import sys\n",
                "from glob import glob\n",
                "import torch\n",
                "import cv2\n",
                "\n",
                "from model.autoencoder import AutoEncoder\n",
                "from utils.config import cm"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "cm.load('/Users/laiyuchun/Desktop/Autoencoder/setting.cfg')\n",
                "cm['ROOT']['DATASET']\n",
                "dataset_root = os.path.join(os.getcwd(), cm['ROOT']['DATASET'])\n",
                "para_root = os.path.join(os.getcwd(), cm['ROOT']['PARA'])\n",
                "test_case_root = os.path.join(os.getcwd(), cm['ROOT']['TEST_CASE'])\n",
                "print(dataset_root, para_root, test_case_root)\n",
                "\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/Users/laiyuchun/Desktop/Autoencoder/dataset /Users/laiyuchun/Desktop/Autoencoder/para/autoencoder_v2.pt /Users/laiyuchun/Desktop/Autoencoder/test_case\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model = AutoEncoder(3, 2, mode='linear').to(device)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#TODO: add feedforward test\n",
                "with torch.no_grad():\n",
                "    pass"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "source": [
                "#TODO: add inference\n",
                "model = torch.load(para_root, map_location=device)\n",
                "optimizer = torch.optim.Adam(\n",
                "    model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
                "loss_F = torch.nn.MSELoss()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "source": [
                "files = glob(os.path.join(test_case_root, '*'))\n",
                "files"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['/Users/laiyuchun/Desktop/Autoencoder/test_case/camera_shift.png',\n",
                            " '/Users/laiyuchun/Desktop/Autoencoder/test_case/screen_change.png',\n",
                            " '/Users/laiyuchun/Desktop/Autoencoder/test_case/normal.png']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 36
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "source": [
                "tmp = {}\n",
                "for file in files:\n",
                "    img = cv2.imread(file)\n",
                "    img = img[200:800, 250:600]\n",
                "    img = img / 255\n",
                "    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
                "    img = torch.Tensor(img).reshape(1, 3, 256, 256)\n",
                "    pred = model(img)\n",
                "    loss = loss_F(img, pred)\n",
                "    tmp[file] = loss\n",
                "\n",
                "tmp"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'/Users/laiyuchun/Desktop/Autoencoder/test_case/camera_shift.png': tensor(0.0044, grad_fn=<MseLossBackward>),\n",
                            " '/Users/laiyuchun/Desktop/Autoencoder/test_case/screen_change.png': tensor(0.0050, grad_fn=<MseLossBackward>),\n",
                            " '/Users/laiyuchun/Desktop/Autoencoder/test_case/normal.png': tensor(0.0026, grad_fn=<MseLossBackward>)}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 39
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.5 64-bit ('TensorFlow': conda)"
        },
        "interpreter": {
            "hash": "e60a17d048fde2b3038d3be4d254ddb0397375ab18d2d3750e317b2cfc1901aa"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}